"""
AgentVaultâ„¢ Advanced Storage Orchestrator
Production-ready orchestration with advanced routing and optimization
Author: Dwiref Sharma
Contact: DwirefS@SapientEdge.io
"""

import asyncio
import hashlib
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum
import numpy as np
from collections import defaultdict, deque
import aioredis
import logging
from concurrent.futures import ThreadPoolExecutor
import msgpack

from ..storage.anf_manager import ANFManager, ANFVolume
from ..storage.tier_manager import TierManager, StorageTier
from ..cache.distributed_cache import DistributedCache
from ..ml.agent_dna import AgentDNAProfiler
from ..ml.cognitive_balancer import CognitiveLoadBalancer
from ..security.encryption_manager import EncryptionManager
from ..monitoring.metrics_collector import MetricsCollector

logger = logging.getLogger(__name__)


class RoutingStrategy(Enum):
    """Advanced routing strategies"""
    LATENCY_OPTIMIZED = "latency_optimized"
    COST_OPTIMIZED = "cost_optimized"
    THROUGHPUT_OPTIMIZED = "throughput_optimized"
    BALANCED = "balanced"
    COMPLIANCE_AWARE = "compliance_aware"
    ML_OPTIMIZED = "ml_optimized"


class DataClassification(Enum):
    """Data classification for compliance and routing"""
    PUBLIC = "public"
    INTERNAL = "internal"
    CONFIDENTIAL = "confidential"
    RESTRICTED = "restricted"
    PII = "pii"
    PHI = "phi"
    FINANCIAL = "financial"


@dataclass
class StorageMetrics:
    """Real-time storage metrics"""
    timestamp: datetime
    latency_ms: float
    throughput_mbps: float
    iops: int
    queue_depth: int
    error_rate: float
    cache_hit_rate: float
    tier_distribution: Dict[StorageTier, float]


@dataclass
class RoutingDecision:
    """Routing decision with reasoning"""
    tier: StorageTier
    volume: ANFVolume
    strategy: RoutingStrategy
    confidence: float
    reasoning: str
    predicted_latency_ms: float
    estimated_cost: float
    compliance_met: bool
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class PrefetchRequest:
    """Prefetch request for predictive loading"""
    agent_id: str
    keys: List[str]
    priority: int
    deadline: datetime
    source_tier: StorageTier
    target_tier: StorageTier


class AdvancedStorageOrchestrator:
    """
    Production-ready storage orchestrator with advanced features:
    - Multi-strategy routing with ML optimization
    - Predictive prefetching and caching
    - Compliance-aware data placement
    - Real-time performance optimization
    - Distributed transaction support
    - Advanced monitoring and analytics
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        
        # Core components
        self.anf_manager = ANFManager(config)
        self.tier_manager = TierManager(config)
        self.cache = DistributedCache(config)
        self.dna_profiler = AgentDNAProfiler()
        self.load_balancer = CognitiveLoadBalancer(config)
        self.encryption_manager = EncryptionManager(config)
        self.metrics_collector = MetricsCollector()
        
        # Advanced components
        self.routing_strategies: Dict[RoutingStrategy, Any] = {}
        self.data_classifications: Dict[str, DataClassification] = {}
        self.active_transactions: Dict[str, Any] = {}
        self.prefetch_queue: asyncio.Queue = asyncio.Queue()
        self.performance_history: deque = deque(maxlen=10000)
        
        # Performance optimization
        self.tier_latencies: Dict[StorageTier, deque] = defaultdict(lambda: deque(maxlen=1000))
        self.tier_costs: Dict[StorageTier, float] = {}
        self.hot_data_tracker: Dict[str, int] = defaultdict(int)
        
        # Thread pool for CPU-intensive operations
        self.executor = ThreadPoolExecutor(max_workers=config.get('worker_threads', 10))
        
        # Background tasks
        self._running = False
        self._background_tasks: List[asyncio.Task] = []
        
    async def initialize(self) -> None:
        """Initialize all components with production checks"""
        logger.info("Initializing Advanced Storage Orchestrator...")
        
        try:
            # Initialize core components
            await asyncio.gather(
                self.anf_manager.initialize(),
                self.tier_manager.initialize(),
                self.cache.initialize(),
                self.load_balancer.initialize()
            )
            
            # Load routing strategies
            self._initialize_routing_strategies()
            
            # Load tier costs from configuration
            self._load_tier_costs()
            
            # Start background tasks
            self._running = True
            self._start_background_tasks()
            
            logger.info("Advanced Storage Orchestrator initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize orchestrator: {str(e)}")
            raise
    
    def _initialize_routing_strategies(self) -> None:
        """Initialize routing strategy handlers"""
        self.routing_strategies = {
            RoutingStrategy.LATENCY_OPTIMIZED: self._route_latency_optimized,
            RoutingStrategy.COST_OPTIMIZED: self._route_cost_optimized,
            RoutingStrategy.THROUGHPUT_OPTIMIZED: self._route_throughput_optimized,
            RoutingStrategy.BALANCED: self._route_balanced,
            RoutingStrategy.COMPLIANCE_AWARE: self._route_compliance_aware,
            RoutingStrategy.ML_OPTIMIZED: self._route_ml_optimized
        }
    
    def _load_tier_costs(self) -> None:
        """Load storage tier costs from configuration"""
        self.tier_costs = {
            StorageTier.ULTRA: self.config.get('tier_costs', {}).get('ultra', 0.50),
            StorageTier.PREMIUM: self.config.get('tier_costs', {}).get('premium', 0.25),
            StorageTier.STANDARD: self.config.get('tier_costs', {}).get('standard', 0.10),
            StorageTier.COOL: self.config.get('tier_costs', {}).get('cool', 0.05),
            StorageTier.ARCHIVE: self.config.get('tier_costs', {}).get('archive', 0.01)
        }
    
    def _start_background_tasks(self) -> None:
        """Start background optimization tasks"""
        self._background_tasks = [
            asyncio.create_task(self._prefetch_worker()),
            asyncio.create_task(self._performance_monitor()),
            asyncio.create_task(self._hot_data_optimizer()),
            asyncio.create_task(self._compliance_scanner()),
            asyncio.create_task(self._cost_optimizer())
        ]
    
    async def process_request(
        self,
        request: Dict[str, Any],
        strategy: Optional[RoutingStrategy] = None
    ) -> Dict[str, Any]:
        """
        Process storage request with advanced routing
        
        Args:
            request: Storage request with operation details
            strategy: Optional routing strategy override
            
        Returns:
            Response with operation results and metrics
        """
        start_time = time.time()
        
        try:
            # Extract request details
            agent_id = request['agent_id']
            operation = request['operation']
            key = request['key']
            
            # Get agent profile for optimization
            agent_profile = await self.dna_profiler.get_agent_profile(agent_id)
            
            # Determine data classification
            classification = await self._classify_data(request)
            
            # Select routing strategy
            if not strategy:
                strategy = await self._select_optimal_strategy(
                    agent_profile, 
                    classification,
                    operation
                )
            
            # Make routing decision
            routing_decision = await self._make_routing_decision(
                request,
                agent_profile,
                classification,
                strategy
            )
            
            # Execute operation
            result = await self._execute_operation(
                request,
                routing_decision
            )
            
            # Record metrics
            latency_ms = (time.time() - start_time) * 1000
            await self._record_metrics(
                agent_id,
                operation,
                routing_decision,
                latency_ms,
                result.get('success', False)
            )
            
            # Update hot data tracker
            self.hot_data_tracker[key] += 1
            
            # Trigger prefetch if needed
            if operation == 'read' and result.get('success'):
                await self._trigger_prefetch(agent_id, key, agent_profile)
            
            return {
                **result,
                'routing': {
                    'strategy': strategy.value,
                    'tier': routing_decision.tier.value,
                    'confidence': routing_decision.confidence,
                    'reasoning': routing_decision.reasoning
                },
                'metrics': {
                    'latency_ms': latency_ms,
                    'predicted_latency_ms': routing_decision.predicted_latency_ms,
                    'classification': classification.value
                }
            }
            
        except Exception as e:
            logger.error(f"Error processing request: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'latency_ms': (time.time() - start_time) * 1000
            }
    
    async def _classify_data(self, request: Dict[str, Any]) -> DataClassification:
        """Classify data for compliance and routing decisions"""
        # Check for explicit classification
        if 'classification' in request.get('metadata', {}):
            return DataClassification(request['metadata']['classification'])
        
        # Analyze key patterns
        key = request['key'].lower()
        
        if any(pattern in key for pattern in ['pii', 'personal', 'user_data']):
            return DataClassification.PII
        elif any(pattern in key for pattern in ['phi', 'health', 'medical']):
            return DataClassification.PHI
        elif any(pattern in key for pattern in ['financial', 'payment', 'transaction']):
            return DataClassification.FINANCIAL
        elif any(pattern in key for pattern in ['confidential', 'secret']):
            return DataClassification.CONFIDENTIAL
        elif any(pattern in key for pattern in ['restricted', 'classified']):
            return DataClassification.RESTRICTED
        elif any(pattern in key for pattern in ['internal', 'private']):
            return DataClassification.INTERNAL
        else:
            return DataClassification.PUBLIC
    
    async def _select_optimal_strategy(
        self,
        agent_profile: Dict[str, Any],
        classification: DataClassification,
        operation: str
    ) -> RoutingStrategy:
        """Select optimal routing strategy based on context"""
        
        # Compliance takes precedence
        if classification in [DataClassification.PHI, DataClassification.PII, 
                            DataClassification.FINANCIAL]:
            return RoutingStrategy.COMPLIANCE_AWARE
        
        # Check agent profile preferences
        if agent_profile:
            if agent_profile.get('latency_sensitive', False):
                return RoutingStrategy.LATENCY_OPTIMIZED
            elif agent_profile.get('cost_sensitive', False):
                return RoutingStrategy.COST_OPTIMIZED
            elif agent_profile.get('ml_optimized', False):
                return RoutingStrategy.ML_OPTIMIZED
        
        # Default based on operation
        if operation in ['read', 'list']:
            return RoutingStrategy.LATENCY_OPTIMIZED
        elif operation == 'write':
            return RoutingStrategy.THROUGHPUT_OPTIMIZED
        else:
            return RoutingStrategy.BALANCED
    
    async def _make_routing_decision(
        self,
        request: Dict[str, Any],
        agent_profile: Dict[str, Any],
        classification: DataClassification,
        strategy: RoutingStrategy
    ) -> RoutingDecision:
        """Make routing decision using selected strategy"""
        
        # Get strategy handler
        strategy_handler = self.routing_strategies.get(strategy)
        if not strategy_handler:
            strategy_handler = self._route_balanced
        
        # Execute strategy
        return await strategy_handler(
            request,
            agent_profile,
            classification
        )
    
    async def _route_latency_optimized(
        self,
        request: Dict[str, Any],
        agent_profile: Dict[str, Any],
        classification: DataClassification
    ) -> RoutingDecision:
        """Route for minimum latency"""
        
        # Get current tier latencies
        tier_latencies = {}
        for tier in StorageTier:
            latencies = self.tier_latencies[tier]
            if latencies:
                tier_latencies[tier] = np.mean(list(latencies))
            else:
                # Default latencies
                tier_latencies[tier] = {
                    StorageTier.ULTRA: 0.1,
                    StorageTier.PREMIUM: 1.0,
                    StorageTier.STANDARD: 10.0,
                    StorageTier.COOL: 100.0,
                    StorageTier.ARCHIVE: 1000.0
                }[tier]
        
        # Select fastest tier that meets requirements
        eligible_tiers = await self._get_eligible_tiers(classification)
        fastest_tier = min(eligible_tiers, key=lambda t: tier_latencies[t])
        
        # Get best volume in tier
        volume = await self.anf_manager.get_optimal_volume(
            request['agent_id'],
            fastest_tier
        )
        
        return RoutingDecision(
            tier=fastest_tier,
            volume=volume,
            strategy=RoutingStrategy.LATENCY_OPTIMIZED,
            confidence=0.95,
            reasoning=f"Selected {fastest_tier.value} for minimum latency ({tier_latencies[fastest_tier]:.2f}ms)",
            predicted_latency_ms=tier_latencies[fastest_tier],
            estimated_cost=self._calculate_cost(request, fastest_tier),
            compliance_met=True
        )
    
    async def _route_cost_optimized(
        self,
        request: Dict[str, Any],
        agent_profile: Dict[str, Any],
        classification: DataClassification
    ) -> RoutingDecision:
        """Route for minimum cost while meeting SLA"""
        
        # Get SLA requirements
        max_latency_ms = agent_profile.get('sla_latency_ms', 100)
        
        # Get eligible tiers
        eligible_tiers = await self._get_eligible_tiers(classification)
        
        # Filter by SLA
        sla_tiers = []
        for tier in eligible_tiers:
            latencies = self.tier_latencies[tier]
            if latencies and np.mean(list(latencies)) <= max_latency_ms:
                sla_tiers.append(tier)
        
        if not sla_tiers:
            sla_tiers = eligible_tiers  # Fallback if no tier meets SLA
        
        # Select cheapest tier
        cheapest_tier = min(sla_tiers, key=lambda t: self.tier_costs[t])
        
        # Get best volume
        volume = await self.anf_manager.get_optimal_volume(
            request['agent_id'],
            cheapest_tier
        )
        
        return RoutingDecision(
            tier=cheapest_tier,
            volume=volume,
            strategy=RoutingStrategy.COST_OPTIMIZED,
            confidence=0.90,
            reasoning=f"Selected {cheapest_tier.value} for minimum cost (${self.tier_costs[cheapest_tier]:.3f}/GB)",
            predicted_latency_ms=np.mean(list(self.tier_latencies[cheapest_tier])) if self.tier_latencies[cheapest_tier] else 10.0,
            estimated_cost=self._calculate_cost(request, cheapest_tier),
            compliance_met=True
        )
    
    async def _route_throughput_optimized(
        self,
        request: Dict[str, Any],
        agent_profile: Dict[str, Any],
        classification: DataClassification
    ) -> RoutingDecision:
        """Route for maximum throughput"""
        
        # Get current volume performance metrics
        volume_metrics = await self.anf_manager.get_volume_metrics()
        
        # Find volume with best throughput
        best_volume = None
        best_throughput = 0
        best_tier = StorageTier.PREMIUM
        
        eligible_tiers = await self._get_eligible_tiers(classification)
        
        for tier in eligible_tiers:
            volumes = await self.anf_manager.get_volumes_by_tier(tier)
            for volume in volumes:
                metrics = volume_metrics.get(volume.id, {})
                throughput = metrics.get('throughput_mbps', 0)
                
                if throughput > best_throughput:
                    best_throughput = throughput
                    best_volume = volume
                    best_tier = tier
        
        if not best_volume:
            # Fallback to creating new volume
            best_tier = StorageTier.PREMIUM
            best_volume = await self.anf_manager.get_optimal_volume(
                request['agent_id'],
                best_tier
            )
        
        return RoutingDecision(
            tier=best_tier,
            volume=best_volume,
            strategy=RoutingStrategy.THROUGHPUT_OPTIMIZED,
            confidence=0.85,
            reasoning=f"Selected volume with {best_throughput:.2f} MB/s throughput",
            predicted_latency_ms=5.0,  # Estimate
            estimated_cost=self._calculate_cost(request, best_tier),
            compliance_met=True
        )
    
    async def _route_balanced(
        self,
        request: Dict[str, Any],
        agent_profile: Dict[str, Any],
        classification: DataClassification
    ) -> RoutingDecision:
        """Balance between latency, cost, and throughput"""
        
        eligible_tiers = await self._get_eligible_tiers(classification)
        
        # Calculate scores for each tier
        tier_scores = {}
        
        for tier in eligible_tiers:
            # Latency score (normalized, lower is better)
            latencies = self.tier_latencies[tier]
            latency = np.mean(list(latencies)) if latencies else 10.0
            latency_score = 1.0 / (1.0 + latency / 10.0)  # Normalize to 0-1
            
            # Cost score (normalized, lower is better)
            cost = self.tier_costs[tier]
            cost_score = 1.0 / (1.0 + cost)
            
            # Capacity score
            volumes = await self.anf_manager.get_volumes_by_tier(tier)
            capacity_score = min(1.0, len(volumes) / 10.0)  # More volumes = better
            
            # Combined score
            tier_scores[tier] = (
                0.4 * latency_score +
                0.3 * cost_score +
                0.3 * capacity_score
            )
        
        # Select best tier
        best_tier = max(tier_scores, key=tier_scores.get)
        
        # Get volume
        volume = await self.anf_manager.get_optimal_volume(
            request['agent_id'],
            best_tier
        )
        
        return RoutingDecision(
            tier=best_tier,
            volume=volume,
            strategy=RoutingStrategy.BALANCED,
            confidence=tier_scores[best_tier],
            reasoning=f"Balanced selection with score {tier_scores[best_tier]:.2f}",
            predicted_latency_ms=np.mean(list(self.tier_latencies[best_tier])) if self.tier_latencies[best_tier] else 10.0,
            estimated_cost=self._calculate_cost(request, best_tier),
            compliance_met=True
        )
    
    async def _route_compliance_aware(
        self,
        request: Dict[str, Any],
        agent_profile: Dict[str, Any],
        classification: DataClassification
    ) -> RoutingDecision:
        """Route based on compliance requirements"""
        
        # Compliance tier mapping
        compliance_tiers = {
            DataClassification.PHI: [StorageTier.ULTRA, StorageTier.PREMIUM],
            DataClassification.PII: [StorageTier.ULTRA, StorageTier.PREMIUM],
            DataClassification.FINANCIAL: [StorageTier.ULTRA, StorageTier.PREMIUM],
            DataClassification.RESTRICTED: [StorageTier.PREMIUM, StorageTier.STANDARD],
            DataClassification.CONFIDENTIAL: [StorageTier.PREMIUM, StorageTier.STANDARD],
            DataClassification.INTERNAL: [StorageTier.STANDARD, StorageTier.COOL],
            DataClassification.PUBLIC: list(StorageTier)
        }
        
        allowed_tiers = compliance_tiers.get(classification, list(StorageTier))
        
        # Select best tier from allowed
        if StorageTier.PREMIUM in allowed_tiers:
            selected_tier = StorageTier.PREMIUM
        elif StorageTier.STANDARD in allowed_tiers:
            selected_tier = StorageTier.STANDARD
        else:
            selected_tier = allowed_tiers[0]
        
        # Get compliant volume
        volume = await self.anf_manager.get_compliant_volume(
            request['agent_id'],
            selected_tier,
            classification.value
        )
        
        return RoutingDecision(
            tier=selected_tier,
            volume=volume,
            strategy=RoutingStrategy.COMPLIANCE_AWARE,
            confidence=1.0,
            reasoning=f"Compliance requirement for {classification.value} data",
            predicted_latency_ms=10.0,
            estimated_cost=self._calculate_cost(request, selected_tier),
            compliance_met=True,
            metadata={'compliance': classification.value}
        )
    
    async def _route_ml_optimized(
        self,
        request: Dict[str, Any],
        agent_profile: Dict[str, Any],
        classification: DataClassification
    ) -> RoutingDecision:
        """Use ML model to predict optimal routing"""
        
        # Get ML prediction
        prediction = await self.load_balancer.predict_optimal_placement(
            agent_id=request['agent_id'],
            data_size=len(str(request.get('data', ''))),
            access_pattern=agent_profile.get('access_pattern', {}),
            current_load=await self._get_system_load()
        )
        
        selected_tier = StorageTier(prediction['tier'])
        
        # Validate against compliance
        eligible_tiers = await self._get_eligible_tiers(classification)
        if selected_tier not in eligible_tiers:
            # Fall back to best eligible tier
            selected_tier = eligible_tiers[0]
        
        # Get volume
        volume = await self.anf_manager.get_optimal_volume(
            request['agent_id'],
            selected_tier
        )
        
        return RoutingDecision(
            tier=selected_tier,
            volume=volume,
            strategy=RoutingStrategy.ML_OPTIMIZED,
            confidence=prediction.get('confidence', 0.8),
            reasoning=f"ML model prediction with {prediction.get('confidence', 0.8):.1%} confidence",
            predicted_latency_ms=prediction.get('predicted_latency', 10.0),
            estimated_cost=self._calculate_cost(request, selected_tier),
            compliance_met=True,
            metadata={'ml_model': prediction.get('model_version', 'v1')}
        )
    
    async def _get_eligible_tiers(
        self,
        classification: DataClassification
    ) -> List[StorageTier]:
        """Get tiers eligible for data classification"""
        
        # Define compliance requirements
        if classification in [DataClassification.PHI, DataClassification.PII]:
            return [StorageTier.ULTRA, StorageTier.PREMIUM]
        elif classification == DataClassification.FINANCIAL:
            return [StorageTier.ULTRA, StorageTier.PREMIUM]
        elif classification in [DataClassification.RESTRICTED, DataClassification.CONFIDENTIAL]:
            return [StorageTier.PREMIUM, StorageTier.STANDARD]
        else:
            return list(StorageTier)
    
    def _calculate_cost(
        self,
        request: Dict[str, Any],
        tier: StorageTier
    ) -> float:
        """Calculate estimated cost for storage operation"""
        
        # Get data size
        data_size_gb = 0
        if 'data' in request:
            data_size_gb = len(str(request['data'])) / (1024**3)
        
        # Base storage cost
        storage_cost = data_size_gb * self.tier_costs[tier]
        
        # Operation cost (simplified)
        operation_cost = {
            'write': 0.001,
            'read': 0.0001,
            'delete': 0.0001,
            'list': 0.00001
        }.get(request['operation'], 0.0001)
        
        return storage_cost + operation_cost
    
    async def _execute_operation(
        self,
        request: Dict[str, Any],
        routing: RoutingDecision
    ) -> Dict[str, Any]:
        """Execute storage operation with routing decision"""
        
        operation = request['operation']
        
        # Add routing metadata to request
        enhanced_request = {
            **request,
            'tier': routing.tier,
            'volume': routing.volume,
            'routing_metadata': {
                'strategy': routing.strategy.value,
                'confidence': routing.confidence,
                'compliance': routing.compliance_met
            }
        }
        
        # Route to appropriate handler
        if operation == 'write':
            return await self._execute_write(enhanced_request)
        elif operation == 'read':
            return await self._execute_read(enhanced_request)
        elif operation == 'delete':
            return await self._execute_delete(enhanced_request)
        elif operation == 'list':
            return await self._execute_list(enhanced_request)
        else:
            raise ValueError(f"Unknown operation: {operation}")
    
    async def _execute_write(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Execute write operation with advanced features"""
        
        try:
            # Encrypt data if needed
            data = request['data']
            if self.config.get('encryption_enabled', True):
                data = await self.encryption_manager.encrypt(
                    data,
                    request['agent_id']
                )
            
            # Compress data if beneficial
            compressed_data = await self._compress_if_beneficial(data)
            
            # Write to primary storage
            result = await self.tier_manager.write_data(
                key=request['key'],
                data=compressed_data,
                tier=request['tier'],
                volume=request['volume'],
                metadata={
                    **request.get('metadata', {}),
                    'compressed': compressed_data != data,
                    'encrypted': self.config.get('encryption_enabled', True),
                    'routing': request['routing_metadata']
                }
            )
            
            # Update cache if successful
            if result['success']:
                await self.cache.set(
                    request['key'],
                    data,  # Cache uncompressed data
                    ttl=self._calculate_cache_ttl(request)
                )
                
                # Schedule replication if needed
                if request.get('replicate', False):
                    await self._schedule_replication(request)
            
            return result
            
        except Exception as e:
            logger.error(f"Write operation failed: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    async def _execute_read(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Execute read operation with caching and prefetch"""
        
        try:
            # Check cache first
            cached_data = await self.cache.get(request['key'])
            if cached_data:
                return {
                    'success': True,
                    'data': cached_data,
                    'cache_hit': True,
                    'source': 'cache'
                }
            
            # Read from storage
            result = await self.tier_manager.read_data(
                key=request['key'],
                tier=request.get('tier'),
                volume=request.get('volume')
            )
            
            if result['success']:
                data = result['data']
                
                # Decompress if needed
                if result.get('metadata', {}).get('compressed'):
                    data = await self._decompress_data(data)
                
                # Decrypt if needed
                if result.get('metadata', {}).get('encrypted'):
                    data = await self.encryption_manager.decrypt(
                        data,
                        request['agent_id']
                    )
                
                # Update cache
                await self.cache.set(
                    request['key'],
                    data,
                    ttl=self._calculate_cache_ttl(request)
                )
                
                result['data'] = data
                result['cache_hit'] = False
            
            return result
            
        except Exception as e:
            logger.error(f"Read operation failed: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    async def _execute_delete(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Execute delete operation with cache invalidation"""
        
        try:
            # Delete from storage
            result = await self.tier_manager.delete_data(
                key=request['key'],
                tier=request.get('tier'),
                volume=request.get('volume')
            )
            
            # Invalidate cache
            if result['success']:
                await self.cache.delete(request['key'])
            
            return result
            
        except Exception as e:
            logger.error(f"Delete operation failed: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    async def _execute_list(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Execute list operation with pagination support"""
        
        try:
            # Get list parameters
            prefix = request.get('key', '')
            limit = request.get('limit', 1000)
            offset = request.get('offset', 0)
            
            # List from storage
            result = await self.tier_manager.list_data(
                prefix=prefix,
                tier=request.get('tier'),
                volume=request.get('volume'),
                limit=limit,
                offset=offset
            )
            
            return result
            
        except Exception as e:
            logger.error(f"List operation failed: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    async def _compress_if_beneficial(self, data: Any) -> Any:
        """Compress data if it reduces size significantly"""
        
        try:
            # Serialize data
            if isinstance(data, (dict, list)):
                serialized = msgpack.packb(data)
            else:
                serialized = str(data).encode()
            
            # Check if compression is beneficial
            if len(serialized) < 1024:  # Don't compress small data
                return data
            
            # Compress using zstd
            import zstandard as zstd
            cctx = zstd.ZstdCompressor(level=3)
            compressed = cctx.compress(serialized)
            
            # Check compression ratio
            ratio = len(compressed) / len(serialized)
            if ratio < 0.9:  # At least 10% reduction
                return compressed
            else:
                return data
                
        except Exception as e:
            logger.warning(f"Compression failed: {str(e)}")
            return data
    
    async def _decompress_data(self, data: bytes) -> Any:
        """Decompress data"""
        
        try:
            import zstandard as zstd
            dctx = zstd.ZstdDecompressor()
            decompressed = dctx.decompress(data)
            
            # Try to deserialize
            try:
                return msgpack.unpackb(decompressed)
            except:
                return decompressed.decode()
                
        except Exception as e:
            logger.warning(f"Decompression failed: {str(e)}")
            return data
    
    def _calculate_cache_ttl(self, request: Dict[str, Any]) -> int:
        """Calculate appropriate cache TTL based on data characteristics"""
        
        # Default TTL
        default_ttl = 3600  # 1 hour
        
        # Adjust based on key patterns
        key = request['key'].lower()
        
        if 'temp' in key or 'tmp' in key:
            return 300  # 5 minutes for temporary data
        elif 'config' in key or 'setting' in key:
            return 86400  # 24 hours for configuration
        elif 'embedding' in key or 'vector' in key:
            return 604800  # 7 days for embeddings
        elif 'model' in key:
            return 2592000  # 30 days for models
        
        return default_ttl
    
    async def _trigger_prefetch(
        self,
        agent_id: str,
        key: str,
        agent_profile: Dict[str, Any]
    ) -> None:
        """Trigger predictive prefetch based on access patterns"""
        
        # Get predicted next keys
        predictions = await self.dna_profiler.predict_next_keys(
            agent_id,
            current_key=key,
            limit=5
        )
        
        if predictions:
            # Create prefetch request
            prefetch_request = PrefetchRequest(
                agent_id=agent_id,
                keys=predictions['keys'],
                priority=predictions.get('confidence', 0.5) * 10,
                deadline=datetime.utcnow() + timedelta(seconds=30),
                source_tier=StorageTier.STANDARD,
                target_tier=StorageTier.PREMIUM
            )
            
            # Add to prefetch queue
            await self.prefetch_queue.put(prefetch_request)
    
    async def _prefetch_worker(self) -> None:
        """Background worker for predictive prefetching"""
        
        while self._running:
            try:
                # Get prefetch request
                request = await asyncio.wait_for(
                    self.prefetch_queue.get(),
                    timeout=1.0
                )
                
                # Execute prefetch
                for key in request.keys:
                    try:
                        # Check if already in fast tier
                        location = await self.tier_manager.get_data_location(key)
                        
                        if location and location['tier'] not in [StorageTier.ULTRA, StorageTier.PREMIUM]:
                            # Move to faster tier
                            await self.tier_manager.move_data(
                                key=key,
                                source_tier=location['tier'],
                                target_tier=request.target_tier
                            )
                            
                            logger.info(f"Prefetched {key} to {request.target_tier.value}")
                            
                    except Exception as e:
                        logger.warning(f"Prefetch failed for {key}: {str(e)}")
                        
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"Prefetch worker error: {str(e)}")
                await asyncio.sleep(1)
    
    async def _performance_monitor(self) -> None:
        """Monitor and record performance metrics"""
        
        while self._running:
            try:
                # Collect metrics
                metrics = StorageMetrics(
                    timestamp=datetime.utcnow(),
                    latency_ms=await self._measure_latency(),
                    throughput_mbps=await self._measure_throughput(),
                    iops=await self._measure_iops(),
                    queue_depth=self.prefetch_queue.qsize(),
                    error_rate=await self._calculate_error_rate(),
                    cache_hit_rate=await self.cache.get_hit_rate(),
                    tier_distribution=await self._get_tier_distribution()
                )
                
                # Store metrics
                self.performance_history.append(metrics)
                
                # Update tier latencies
                for tier, latency in metrics.tier_distribution.items():
                    self.tier_latencies[tier].append(latency)
                
                # Export to monitoring system
                await self.metrics_collector.record_metrics(metrics)
                
                # Sleep for monitoring interval
                await asyncio.sleep(self.config.get('monitoring_interval', 30))
                
            except Exception as e:
                logger.error(f"Performance monitor error: {str(e)}")
                await asyncio.sleep(30)
    
    async def _hot_data_optimizer(self) -> None:
        """Optimize placement of frequently accessed data"""
        
        while self._running:
            try:
                # Wait for optimization interval
                await asyncio.sleep(self.config.get('optimization_interval', 300))
                
                # Get hot data
                hot_keys = sorted(
                    self.hot_data_tracker.items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:100]  # Top 100 hot keys
                
                for key, access_count in hot_keys:
                    if access_count > 10:  # Threshold for hot data
                        try:
                            # Check current location
                            location = await self.tier_manager.get_data_location(key)
                            
                            if location and location['tier'] not in [StorageTier.ULTRA, StorageTier.PREMIUM]:
                                # Move to faster tier
                                await self.tier_manager.move_data(
                                    key=key,
                                    source_tier=location['tier'],
                                    target_tier=StorageTier.PREMIUM
                                )
                                
                                logger.info(f"Promoted hot data {key} to premium tier")
                                
                        except Exception as e:
                            logger.warning(f"Failed to optimize hot data {key}: {str(e)}")
                
                # Reset counters
                self.hot_data_tracker.clear()
                
            except Exception as e:
                logger.error(f"Hot data optimizer error: {str(e)}")
                await asyncio.sleep(300)
    
    async def _compliance_scanner(self) -> None:
        """Scan for compliance violations and remediate"""
        
        while self._running:
            try:
                # Wait for scan interval
                await asyncio.sleep(self.config.get('compliance_scan_interval', 3600))
                
                logger.info("Starting compliance scan...")
                
                # Get all data locations
                all_data = await self.tier_manager.get_all_data_locations()
                
                violations = []
                
                for key, location in all_data.items():
                    # Classify data
                    classification = await self._classify_data({'key': key})
                    
                    # Check if tier is compliant
                    eligible_tiers = await self._get_eligible_tiers(classification)
                    
                    if location['tier'] not in eligible_tiers:
                        violations.append({
                            'key': key,
                            'current_tier': location['tier'],
                            'classification': classification,
                            'eligible_tiers': eligible_tiers
                        })
                
                # Remediate violations
                for violation in violations:
                    try:
                        target_tier = violation['eligible_tiers'][0]
                        
                        await self.tier_manager.move_data(
                            key=violation['key'],
                            source_tier=violation['current_tier'],
                            target_tier=target_tier
                        )
                        
                        logger.warning(
                            f"Remediated compliance violation: moved {violation['key']} "
                            f"from {violation['current_tier'].value} to {target_tier.value}"
                        )
                        
                    except Exception as e:
                        logger.error(f"Failed to remediate violation for {violation['key']}: {str(e)}")
                
                logger.info(f"Compliance scan complete. Found and remediated {len(violations)} violations")
                
            except Exception as e:
                logger.error(f"Compliance scanner error: {str(e)}")
                await asyncio.sleep(3600)
    
    async def _cost_optimizer(self) -> None:
        """Optimize storage costs by moving cold data to cheaper tiers"""
        
        while self._running:
            try:
                # Wait for optimization interval
                await asyncio.sleep(self.config.get('cost_optimization_interval', 86400))  # Daily
                
                logger.info("Starting cost optimization...")
                
                # Get aged data
                aged_data = await self.tier_manager.get_aged_data(
                    age_threshold_days=self.config.get('cold_data_threshold_days', 30)
                )
                
                total_savings = 0.0
                
                for key, info in aged_data.items():
                    current_tier = info['tier']
                    age_days = info['age_days']
                    size_gb = info['size_gb']
                    
                    # Determine target tier based on age
                    if age_days > 365 and current_tier != StorageTier.ARCHIVE:
                        target_tier = StorageTier.ARCHIVE
                    elif age_days > 90 and current_tier not in [StorageTier.COOL, StorageTier.ARCHIVE]:
                        target_tier = StorageTier.COOL
                    elif age_days > 30 and current_tier in [StorageTier.ULTRA, StorageTier.PREMIUM]:
                        target_tier = StorageTier.STANDARD
                    else:
                        continue
                    
                    # Calculate potential savings
                    current_cost = size_gb * self.tier_costs[current_tier]
                    target_cost = size_gb * self.tier_costs[target_tier]
                    savings = current_cost - target_cost
                    
                    if savings > 0.01:  # Minimum savings threshold
                        try:
                            # Check compliance before moving
                            classification = await self._classify_data({'key': key})
                            eligible_tiers = await self._get_eligible_tiers(classification)
                            
                            if target_tier in eligible_tiers:
                                await self.tier_manager.move_data(
                                    key=key,
                                    source_tier=current_tier,
                                    target_tier=target_tier
                                )
                                
                                total_savings += savings
                                logger.info(
                                    f"Moved {key} from {current_tier.value} to {target_tier.value}, "
                                    f"saving ${savings:.2f}/month"
                                )
                                
                        except Exception as e:
                            logger.warning(f"Failed to optimize {key}: {str(e)}")
                
                logger.info(f"Cost optimization complete. Total monthly savings: ${total_savings:.2f}")
                
            except Exception as e:
                logger.error(f"Cost optimizer error: {str(e)}")
                await asyncio.sleep(86400)
    
    async def _measure_latency(self) -> float:
        """Measure average system latency"""
        # Implementation would measure actual latencies
        return 5.0  # Placeholder
    
    async def _measure_throughput(self) -> float:
        """Measure system throughput in MB/s"""
        # Implementation would measure actual throughput
        return 100.0  # Placeholder
    
    async def _measure_iops(self) -> int:
        """Measure system IOPS"""
        # Implementation would measure actual IOPS
        return 1000  # Placeholder
    
    async def _calculate_error_rate(self) -> float:
        """Calculate recent error rate"""
        # Implementation would track actual errors
        return 0.001  # Placeholder
    
    async def _get_tier_distribution(self) -> Dict[StorageTier, float]:
        """Get data distribution across tiers"""
        # Implementation would calculate actual distribution
        return {
            StorageTier.ULTRA: 5.0,
            StorageTier.PREMIUM: 30.0,
            StorageTier.STANDARD: 50.0,
            StorageTier.COOL: 10.0,
            StorageTier.ARCHIVE: 5.0
        }
    
    async def _get_system_load(self) -> Dict[str, Any]:
        """Get current system load metrics"""
        return {
            'cpu_percent': 45.0,
            'memory_percent': 60.0,
            'io_wait': 5.0,
            'queue_depth': self.prefetch_queue.qsize()
        }
    
    async def _schedule_replication(self, request: Dict[str, Any]) -> None:
        """Schedule data replication for durability"""
        # Implementation would schedule async replication
        pass
    
    async def _record_metrics(
        self,
        agent_id: str,
        operation: str,
        routing: RoutingDecision,
        latency_ms: float,
        success: bool
    ) -> None:
        """Record operation metrics"""
        
        # Record to tier latencies
        if success:
            self.tier_latencies[routing.tier].append(latency_ms)
        
        # Export to metrics collector
        await self.metrics_collector.record_operation(
            agent_id=agent_id,
            operation=operation,
            tier=routing.tier.value,
            latency_ms=latency_ms,
            success=success,
            strategy=routing.strategy.value
        )
    
    async def shutdown(self) -> None:
        """Gracefully shutdown orchestrator"""
        logger.info("Shutting down Advanced Storage Orchestrator...")
        
        self._running = False
        
        # Cancel background tasks
        for task in self._background_tasks:
            task.cancel()
        
        # Wait for tasks to complete
        await asyncio.gather(*self._background_tasks, return_exceptions=True)
        
        # Shutdown components
        await asyncio.gather(
            self.anf_manager.shutdown(),
            self.tier_manager.shutdown(),
            self.cache.shutdown(),
            self.load_balancer.shutdown()
        )
        
        # Shutdown thread pool
        self.executor.shutdown(wait=True)
        
        logger.info("Advanced Storage Orchestrator shutdown complete")